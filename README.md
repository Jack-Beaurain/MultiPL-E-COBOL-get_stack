The stack is a massive dataset specifically designed for training large language models (LLMs) in the field of Artificial Intelligence to understand and generate code. It consists of 3.1 terabytes of source code written in 30 different programming languages. The purpose of creating the stack is to foster open and responsible research on LLMs for code-related tasks.
By training 350 million-parameter decoders on various subsets of code from the stack text2code benchmarks have achieved promising results. These benchmarks evaluate the LLM's ability to convert natural language prompts into executable code accurately.
